# -*- coding: utf-8 -*-
"""VOID Diffusion (Unfiltred Stable Diffusion) - v0.9.12

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MRwvDBNc4jhlEXSAtdLe49A4C1k35pgp

#<font color="#943fd9">VOID Diffusion (Unfiltred Stable Diffusion)</font>&nbsp;<small>**v0.9.12**</small><br>

---
Latest version: https://voidops.com/diffusion

Discord: https://discord.gg/yYEaTwuWFZ

Contact: `Beyondo#0130` or beyondo@voidops.com


<img width="512" src="https://user-images.githubusercontent.com/58893646/210701459-57d923b3-1e60-40bc-bb67-0975107ce97f.png"></img>


ü§ó If you feel like it, you can always <a href="https://www.buymeacoffee.com/beyondo" target="_blank">buy me a coffee</a>

‚ù§Ô∏è Please star the project here: https://github.com/Beyondo/void-diffusion

Warning: NSFW filter is disabled in all models.

---
Wanna make ChatGPT your puppet? Check out [VOID Chat](https://void.chat/app) where you get god-like AI powers that were only meant for OpenAI devs, all for free. With features like subprompts, AI message editing, no moderation blocking, and more. Just install the [VOIDSync browser extension](https://chrome.google.com/webstore/detail/voidsync/hepncmhgcndbojaecbafenjpgkdpikfl) to connect VOID Chat to your currently logged-in ChatGPT account in the browser.

Take for example the subprompt "You are a zombie." using the agent ChaosGPT:

<img width="768" src="https://cdn.discordapp.com/attachments/1122295037775073351/1157365690391605420/image.png"></img>

Unlike the image above, it is better to hover over the AI's output and edit its interactions to begin with a keyword like "Zombie:", "Human:" or "John:" for better enforced results.

Keep in mind: It's a "use at your own risk" deal. Using an alt account is a smart move to avoid potential bans. It bypasses moderation blocking and moderation flags for input, but it does not bypass moderation for output.

So, VOID Chat itself won't get you banned; it's all about what you generate with it. So use it wisely and have fun!

# <font color="white">Setup <small><small><small><small>(Click on arrow to select models or enable inpainting, and other settings)</small></small></small></small></font>
"""

#@title <font color="orange">Install Engine</font>
#@markdown Google Drive Settings
SaveToGoogleDrive = True #@param {type:"boolean"}
SaveDiffusionSettings = True #@param {type:"boolean"}
Directory = "VOID/AI-Gen" #@param {type:"string"}
DevMode = False
Latest = True
Version = "v0.9.12"
import os, shutil
from IPython import get_ipython
try:
  # GDrive
  ShouldSaveToGoogleDrive = False
  if SaveToGoogleDrive:
    from google.colab import drive
    if not os.path.exists("/content/gdrive/MyDrive"):
      drive.mount('/content/gdrive', force_remount=True)
    ShouldSaveToGoogleDrive = True
  # Clone repo
  if os.path.exists("/content/"):
      # In colab
      if os.path.exists("/content/void-diffusion"):
          shutil.rmtree('/content/void-diffusion')
      os.makedirs('/content/void-diffusion')
      os.chdir("/content/void-diffusion")
      if DevMode:
        print("Cloning an unstable version -> ", end="")
        get_ipython().system("git clone https://github.com/Beyondo/void-diffusion.git . &> /dev/null")
      else:
        print("Updating from Beyondo/void-diffusion (%s) -> " % Version, end="")
        get_ipython().system("git clone --depth 1 --branch %s https://github.com/Beyondo/void-diffusion.git . &> /dev/null" % Version)
      print("Done.")
      try: os.chdir("/content/void-diffusion")
      except: print("Couldn't clone the repository. You sure that version exists?")
  try:
    import env
    env.install_vendors()
    from legacy import colab
    import importlib, datetime
    from IPython import display
    from IPython.display import HTML
    importlib.reload(colab)
    colab.save_directory = Directory
    colab.save_settings = SaveDiffusionSettings
    try:
      # Log
      display.display(HTML("<strong><span style='color: green'>Last saved at %s</span></strong>" % datetime.datetime.now().strftime("%H:%M")))
      if not DevMode:
        import requests
        repo_url = "https://api.github.com/repos/Beyondo/void-diffusion"
        response = requests.get(f"{repo_url}/releases/latest")
        if response.status_code == 200:
            data = response.json()
            latest_tag = data["tag_name"]
            if latest_tag != Version:
                Latest = False
                print(f"You are using an older version {Version}. Update to the latest version {latest_tag} from here https://voidops.com/diffusion")
            else:
                print(f"You are using the latest version {latest_tag}")
        else:
            print("Error getting the latest release tag from GitHub")

    except Exception as e: print(e)
  except Exception as e: print(e)
except KeyboardInterrupt:
  print("You've manually interrupted the Engine installation.")
except Exception as e:
  print(e)

"""## <font color="cyan">Model Selector</font>
---
Model | Type | Prompt accuracy | Quality | NSFW
--- | --- | --- | --- | ---
runwayml/stable-diffusion-v1-5 | <font color="orange">General</font> | ? | 8 | 7 | Yes | Yes|
CompVis/stable-diffusion-v1-4 | <font color="orange">General</font> | ? | 7 | 7
stabilityai/stable-diffusion-2-1 | <font color="orange">General</font> | ? | 6 | 0
SG161222/Realistic_Vision_V2.0 | <font color="#C569FF">Realistic <font color ="red"><small>(need prompting)</small></font> </font> | ? | 10 | 9
darkstorm2150/Protogen_x3.4_Official_Release | <font color="cyan">Photorealistic</font>, <font color="#A169FF">Artistic</font> | ? | 9 | 9
prompthero/openjourney | <font color="#A169FF">Artistic</font> | ? | 8 | 7
naclbit/trinart_stable_diffusion_v2 | <font color="#A169FF">Artistic</font>, <font color="#C569FF">Anime</font> | ? | 7 | 8
hakurei/waifu-diffusion | <font color="#C569FF">Anime</font> | ? | 8 | 8
runwayml/stable-diffusion-inpainting | 512x512 Inpainting | ? | ? | ?

"""

Model = "" #@param ["runwayml/stable-diffusion-v1-5", "CompVis/stable-diffusion-v1-4", "stabilityai/stable-diffusion-2-1", "SG161222/Realistic_Vision_V2.0", "darkstorm2150/Protogen_x3.4_Official_Release", "prompthero/openjourney", "naclbit/trinart_stable_diffusion_v2", "hakurei/waifu-diffusion"] {allow-input: true}
#@markdown <small>You can input a Huggingface model ID or path or select one from the dropdown.<br>Additionally, you can also enter the path or the GDrive URL of a `.ckpt` file.<br>Example 1: /content/gdrive/MyDrive/MyModels/someCheckpoint.ckpt.<br>Example 2: https://drive.google.com/file/d/1-gPNfkD4AaJ3ZlMS-B9nqcnBNGIa7URa (Note that GDrive URL downloads are limited and should be for personal use only)</small>
#@markdown ***
UseInpainting = False #@param {type:"boolean"}
InpaintingModel = "runwayml/stable-diffusion-inpainting" #@param ["runwayml/stable-diffusion-inpainting"] {allow-input: true}
#@markdown ***

import gdown, re, os

def get_first_chkpt_file(directory):
    for filename in os.listdir(directory):
        if filename.endswith(".ckpt"):
            return os.path.join(directory, filename)

    # If no .chkpt file is found
    return None

if "drive.google.com" in Model:
    matched = re.search(r"/d/([a-zA-Z0-9_-]+)", Model)
    if matched:
        file_id = matched.group(1)
        output = file_id + "/"
        gdown.download(id=file_id, output=output, quiet=False)
        first_chkpt_file = get_first_chkpt_file(output)
        if first_chkpt_file == None:
            print("The downloaded file was not a .ckpt.")
        else:
            Model = first_chkpt_file
            print(f"\nNow locking {Model}!")
    else:
        print("Could not download the ckpt from Google Drive.")

import importlib, os, shutil
try:
  from legacy import colab
  try: colab.init(ModelName=Model, InpaintingModel=InpaintingModel if UseInpainting else None)
  except Exception as e:
      print("Error initializing model: ", end="")
      print(e)
except: print("Please play the settings first.")

"""# <font color="#F03000">Text To Image</font>"""

try:
  from legacy import colab, text2img
  import importlib, os, shutil
  if colab.ready:
    importlib.reload(text2img)
    Seed = 0 #@param {type:"number"}
    if Seed == None: Seed = 0
    Width = "512" #@param [128, 256, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024]
    Height = "512" #@param [128, 256, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024]
    Prompt = "RAW photo, a close up portrait photo of 26 y.o woman in wastelander clothes, long haircut, pale skin, slim body, background is city ruins, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3" #@param {type:"string"}
    NegativePrompt = "(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck" #@param {type:"string"}
    GuidanceScale = 13.8 #@param {type:"slider", min:1, max:30, step:0.1}
    Steps = 100 #@param {type:"slider", min:1, max:500, step:1}
    Iterations = 6 #@param {type:"slider", min:1, max:50, step:1}
    Scheduler = "Default" #@param ["Default", "DPMSolverMultistepScheduler", "LMSDiscreteScheduler", "EulerDiscreteScheduler", "PNDMScheduler", "DDIMScheduler"]
    Scale = "2x" #@param ["1x", "2x", "4x", "8x"]
    PostProcessor = "GFPGAN+Real-ESRGAN" #@param ["Real-ESRGAN", "GFPGAN+Real-ESRGAN", "Bicubic"]
    PostParallelism = 3 #@param {type:"slider", min:1, max:4, step:1}
    PostReplaceResultView = True #@param {type:"boolean"}
    Preview = True #@param {type:"boolean"}
    colab.settings["Seed"] = int(Seed)
    colab.settings["Width"] = int(Width)
    colab.settings["Height"] = int(Height)
    colab.settings["Prompt"] = Prompt
    colab.settings["NegativePrompt"] = NegativePrompt
    colab.settings['GuidanceScale'] = float(GuidanceScale)
    colab.settings["Steps"] = Steps
    colab.settings["Iterations"] = Iterations
    colab.settings["Scheduler"] = Scheduler
    colab.settings["Scale"] = Scale
    colab.settings["Upscaler"] = PostProcessor
    if not Latest:
      print("Diffusing using an older version. Update from here https://voidops.com/diffusion")
    text2img.process(ShouldSave=ShouldSaveToGoogleDrive, maxNumJobs=PostParallelism, ShouldPreview=Preview, ReplaceResult=PostReplaceResultView)
except KeyboardInterrupt:
    print("Diffusion was manually interrupted.")
    colab.start_media_server()
except Exception as e:
    if DevMode: print(e)
    colab.prepare("text2img")
#@markdown <small>**Prompt**: What you want to see</small><br>
#@markdown <small>**NegativePrompt**: What you do NOT want to see</small><br>
#@markdown <small>**Iterations**: Number of images you want to generate per prompt</small><br>
#@markdown <small>**PostParallelism**: The number of post jobs that run in parllel. Decrease if you're getting "Scaling failed" errors</small><br>
#@markdown <i><small>**Misconception**: The frames in progress preview **are not the same** as the images generated from lower inference steps</small></i><br>
#@markdown <i><small>**Note**: Using a resolution of 1024x1024 would cause scaling to fail ~90% of the time.</small></i>
#@markdown ***

"""# <font color="#F03000">Image To Image</font>

<img width="512" src="https://cdn.discordapp.com/attachments/1051968627114512455/1061881263977398282/image.png"></img><br>
<small>The image above is a demonstration of how you can enhance and add details to your own art just by adjusting the strength, guidance, and steps carefully.</small>
"""

try:
  from legacy import colab, img2img
  import importlib, os, shutil
  if colab.ready:
    importlib.reload(img2img)
    Seed = 0 #@param {type:"number"}
    if Seed == None: Seed = 0
    Width = "512" #@param [128, 256, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024]
    Height = "512" #@param [128, 256, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960, 1024]
    InitialImageURL = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg" #@param {type:"string"}
    UseLastImageOutputAsInitialImage = False #@param {type:"boolean"}
    Prompt = "A fantasy landscape with a blue river between a desert on the left and grass on the right at night, trending on artstation" #@param {type:"string"}
    NegativePrompt = "boring, simple, morning" #@param {type:"string"}
    Strength = 0.75 #@param {type:"slider", min:0, max:1, step:0.01}
    GuidanceScale = 20 #@param {type:"slider", min:0, max:30, step:0.1}
    Steps = 100 #@param {type:"slider", min:1, max:500, step:1}
    Iterations = 6 #@param {type:"slider", min:1, max:50, step:1}
    Scheduler = "Default" #@param ["Default", "DPMSolverMultistepScheduler", "LMSDiscreteScheduler", "EulerDiscreteScheduler", "PNDMScheduler", "DDIMScheduler"]
    Scale = "2x" #@param ["1x", "2x", "4x", "8x"]
    PostProcessor = "Real-ESRGAN" #@param ["Real-ESRGAN", "GFPGAN+Real-ESRGAN", "Bicubic"]
    PostParallelism = 2 #@param {type:"slider", min:1, max:4, step:1}
    PostReplaceResultView = False #@param {type:"boolean"}
    Preview = True #@param {type:"boolean"}
    colab.settings["Seed"] = int(Seed)
    colab.settings["Width"] = int(Width)
    colab.settings["Height"] = int(Height)
    colab.settings["Prompt"] = Prompt
    colab.settings["NegativePrompt"] = NegativePrompt
    colab.settings['GuidanceScale'] = float(GuidanceScale)
    colab.settings["Strength"] = Strength
    colab.settings["InitialImageURL"] = InitialImageURL
    colab.settings["Steps"] = Steps
    colab.settings["Iterations"] = Iterations
    colab.settings["Scheduler"] = Scheduler
    colab.settings["Scale"] = Scale
    colab.settings["Upscaler"] = PostProcessor
    colab.settings['UseLastOutputAsInitialImage'] = UseLastImageOutputAsInitialImage
    if not Latest:
      print("Diffusing using an older version. Update from here https://voidops.com/diffusion")
    img2img.process(ShouldSave=ShouldSaveToGoogleDrive, maxNumJobs=PostParallelism, ShouldPreview=Preview, ReplaceResult=PostReplaceResultView)
except KeyboardInterrupt:
    print("Diffusion was manually interrupted.")
    colab.start_media_server()
except Exception as e:
  if DevMode:
    print(e)
  colab.prepare("img2img")
#@markdown <small>**Strength**: Controls how much the model should follow the prompt versus the init image. A value of 0 means that the model will ignore the prompt while a value of 1 means that the model will only follow the prompt.</small><br>
#@markdown ***
#@markdown <small>**InitialImageURL**: Use an uploading service like send them to yourself in discord DM then copy your image's URL here.</small><br>
#@markdown ***
#@markdown <small>**PostParallelism**: The number of post jobs that run in parllel. Decrease if you're getting "Scaling failed" errors.</small><br>
#@markdown ***
#@markdown <small>**UseLastImageOutputAsInitialImage**: Automatically use the last output.</small><br>
#@markdown ***

"""  # <font color="#F03000">Inpainting</font>"""

try:
  from legacy import colab, inpaint
  import importlib, os, shutil
  if colab.ready:
    importlib.reload(inpaint)
    #@markdown <b>Prompt</b> is what you want to see, while <b>NegativePrompt</b> is the opposite.
    Seed = 0 #@param {type:"number"}
    if Seed == None: Seed = 0
    UseLastImageOutputAsInitialImage = False #@param {type:"boolean"}
    InitialImageURL = "https://replicate.delivery/pbxt/HtGQBfA5TrqFYZBf0UL18NTqHrzt8UiSIsAkUuMHtjvFDO6p/overture-creations-5sI6fQgYIuo.png" #@param {type:"string"}
    MaskImageURL = "https://replicate.delivery/pbxt/HtGQBqO9MtVbPm0G0K43nsvvjBB0E0PaWOhuNRrRBBT4ttbf/mask.png" #@param {type:"string"}
    Prompt = "Delicious big cake, chocolate, vanilla, caramelle, on a park bench, , g\xE2teau" #@param {type:"string"}
    NegativePrompt = "" #@param {type:"string"}
    #Strength = 0.75 #@param {type:"slider", min:0, max:1, step:0.01}
    GuidanceScale = 30 #@param {type:"slider", min:0, max:30, step:0.1}
    Steps = 60 #@param {type:"slider", min:1, max:500, step:1}
    Iterations = 6 #@param {type:"slider", min:1, max:50, step:1}
    Scheduler = "Default" #@param ["Default", "DPMSolverMultistepScheduler", "LMSDiscreteScheduler", "EulerDiscreteScheduler", "PNDMScheduler", "DDIMScheduler"]
    Scale = "2x" #@param ["1x", "2x", "4x", "8x"]
    PostProcessor = "GFPGAN+Real-ESRGAN" #@param ["Real-ESRGAN", "GFPGAN+Real-ESRGAN", "Bicubic"]
    PostParallelism = 2 #@param {type:"slider", min:1, max:4, step:1}
    PostReplaceResultView = False #@param {type:"boolean"}
    Preview = True #@param {type:"boolean"}
    colab.settings["Seed"] = int(Seed)
    colab.settings["Prompt"] = Prompt
    colab.settings["NegativePrompt"] = NegativePrompt
    colab.settings['GuidanceScale'] = float(GuidanceScale)
    #colab.settings["Strength"] = Strength
    colab.settings["InitialImageURL"] = InitialImageURL
    colab.settings["MaskImageURL"] = MaskImageURL
    colab.settings["Steps"] = Steps
    colab.settings["Iterations"] = Iterations
    colab.settings["Scheduler"] = Scheduler
    colab.settings["Scale"] = Scale
    colab.settings["Upscaler"] = PostProcessor
    colab.settings['UseLastOutputAsInitialImage'] = UseLastImageOutputAsInitialImage
    if not Latest:
      print("Diffusing using an older version. Update from here https://voidops.com/diffusion")
    inpaint.process(ShouldSave=ShouldSaveToGoogleDrive, maxNumJobs=PostParallelism, ShouldPreview=Preview, ReplaceResult=PostReplaceResultView)
except KeyboardInterrupt:
    print("Diffusion was manually interrupted.")
    colab.start_media_server()
except: colab.prepare("inpaint")
#@markdown ***
#@markdown <small>**PostParallelism**: The number of post jobs that run in parllel. Decrease if you're getting "Scaling failed" errors.</small><br>
#@markdown <small>**MaskImageURL**: You need to draw a mask on the image. Black colour for unchanging parts while white color for changing parts.</small><br>

"""# Restart the image server <small><small><small>*(in case crashed)*</small></small></small>"""

try:
  from google.colab.output import eval_js
  from legacy import colab; colab.start_media_server()
  print("All of your images are here: %s" % eval_js("google.colab.kernel.proxyPort(8000)"))
except: print("Setup first.")

"""# <font color="#fc03a1">Model Manager</font>"""

#@title Save the model to Google Drive <small><small>(HuggingFace's compatible / Diffusers)</small></small>
#@markdown **Useful for**<br><small>- Loading your model faster.<br>- If you trained the model yourself, you'd be able to upload it to HuggingFace and share it.</small><br>
ModelName = "MyModel" #@param {type:"string"}
GDriveDirectory = "VOID/Models" #@param {type:"string"}

save_dir = f"/content/gdrive/MyDrive/{GDriveDirectory}/{ModelName}"
print(save_dir)
import os
from legacy import colab
if os.path.exists(save_dir):
  print("Sorry! That directory already exists. Try deleting it manually if you want to override it.")
else:
  colab.pipeline.save_pretrained(save_dir)
  print(f"Your model was saved at `{save_dir}`!")

"""# <font color="orange">Developer notes</font>

**VOID Diffusion v0.9.10 -> v0.9.12 changelog:**
```markdown
- Fixed stuck at Fetching 0% HuggingFace issue
- Fixed SG161222/Realistic_Vision_V2.0 not having an fp16 revision anymore
```

**VOID Diffusion v0.9.9 -> v0.9.10 changelog:**
```markdown
- Added a feature to save models to your Google Drive as Diffusers/HuggingFace-compatible.
- Added the ability to load .safetensors and other binary checkpoints
- Added support for using a shared Google Drive's URL of a checkpoint as a model
```

**VOID Diffusion v0.9.8 -> v0.9.9 changelog:**
```markdown
- Fixed inpainting mode not working
- Added image generation error traceback for bug reporting
```


**VOID Diffusion v0.9.5 -> v0.9.8 changelog:**
```markdown
- Added a checkpoint (.ckpt) loader
- Fixed minor UI issues and added a button to copy the seed
- Included seed in image name
```

**VOID Diffusion v0.9.3 -> v0.9.5 changelog:**
```markdown
- Added SG161222/Realistic_Vision_V2.0 (suggested by thebirdmanjax#5038)
- Fixed upscaling issues for some models
- Included additional config information
```
**VOID Diffusion v0.9 -> v0.9.3 changelog:**
```markdown
- Added DPM, LMS, Euler, PNDM, DDIM schedulers
- Added Protogen photorealistic model
- Fix - Pausing generation will now not cause colab errors
- Fix - Pausing generation will now not kill the image server
- Minor memory improvements
- Added a version checker
```
"""